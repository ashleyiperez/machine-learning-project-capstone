{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Model Development with AWS Sagemaker Built-in Algorithms: Model Productionization to Scheduled Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this notebook assumes raw data was pulled from original source of data: https://data.austintexas.gov/Health-and-Community-Services/Austin-Animal-Center-Intakes/wter-evkm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename file as 'data.csv' to benefit from the pre-processing written for the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert outcome types to binary classification: 'adopted' vs. 'not adopted'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['outcome_type'] = dataset['outcome_type'].replace('Adoption','Adopted')\n",
    "data['outcome_type'] = dataset['outcome_type'].replace('Return to Owner','Not Adopted')\n",
    "data['outcome_type'] = dataset['outcome_type'].replace('Transfer','Not Adopted')\n",
    "data['outcome_type'] = dataset['outcome_type'].replace('Euthanasia','Not Adopted')\n",
    "data['outcome_type'] = dataset['outcome_type'].replace('Died','Not Adopted')\n",
    "data['outcome_type'] = dataset['outcome_type'].replace('Rto-Adopt','Adopted')\n",
    "data['outcome_type'] = dataset['outcome_type'].replace('Missing','Not Adopted')\n",
    "data['outcome_type'] = dataset['outcome_type'].replace('Disposal','Not Adopted')\n",
    "data['outcome_type'] = dataset['outcome_type'].replace('Relocate','Not Adopted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert categorical data to 'category' data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data['outcome_type'] = dataset['outcome_type'].astype(\"category\")\n",
    "data['animal_type'] = dataset['animal_type'].astype(\"category\")\n",
    "data['breed'] = dataset['breed'].astype(\"category\")\n",
    "data['sex_upon_outcome'] = dataset['sex_upon_outcome'].astype(\"category\")\n",
    "data['sex_upon_intake'] = dataset['sex_upon_intake'].astype(\"category\")\n",
    "data['color'] = dataset['color'].astype(\"category\")\n",
    "data['intake_type'] = dataset['intake_type'].astype(\"category\")\n",
    "data['outcome_weekday'] = dataset['outcome_weekday'].astype(\"category\")\n",
    "data['intake_weekday'] = dataset['intake_weekday'].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop columns that are irrelevant for the purposes of this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop('outcome_subtype', axis=1, inplace=True)\n",
    "data.drop('intake_monthyear', axis=1, inplace=True)\n",
    "data.drop('count', axis=1, inplace=True)\n",
    "data.drop('dob_monthyear', axis=1, inplace=True)\n",
    "data.drop('outcome_monthyear', axis=1, inplace=True)\n",
    "data.drop('time_in_shelter', axis=1, inplace=True)\n",
    "data.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "\n",
    "#if don't currently have outcome characteristics documented:\n",
    "\n",
    "#data.drop(labels='outcome_month', axis=1, inplace=True)\n",
    "#data.drop(labels='outcome_year', axis=1, inplace=True)\n",
    "#data.drop(labels='outcome_weekday', axis=1, inplace=True)\n",
    "#data.drop(labels='outcome_hour', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encode the column names to ensure the built-in algorithms are able to interpret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "data = data.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(data.drop('outcome_type', axis=1), data['outcome_type'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encode data for outcome for binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_train = le.fit_transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_val = le.transform(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install and import best model for problem: lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightgbm\n",
      "  Using cached lightgbm-3.3.5-py3-none-manylinux1_x86_64.whl (2.0 MB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from lightgbm) (1.21.6)\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.7/site-packages (from lightgbm) (0.40.0)\n",
      "Requirement already satisfied: scikit-learn!=0.22.0 in /opt/conda/lib/python3.7/site-packages (from lightgbm) (0.22.1)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from lightgbm) (1.4.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn!=0.22.0->lightgbm) (1.2.0)\n",
      "Installing collected packages: lightgbm\n",
      "Successfully installed lightgbm-3.3.5\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train model on data input and monitor losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#using best hyperparameters from hpo output\n",
    "model = lgb.LGBMClassifier(subsample = 1.0, reg_lambda= 1, num_leaves = 180, min_child_weight = 0.1, learning_rate  = 0.1, colsample_bytree = 0.5, boosting_type = 'dart', random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20]\ttraining's binary_logloss: 0.43959\tvalid_0's binary_logloss: 0.452905\n",
      "[40]\ttraining's binary_logloss: 0.403812\tvalid_0's binary_logloss: 0.42421\n",
      "[60]\ttraining's binary_logloss: 0.368745\tvalid_0's binary_logloss: 0.392918\n",
      "[80]\ttraining's binary_logloss: 0.355996\tvalid_0's binary_logloss: 0.382596\n",
      "[100]\ttraining's binary_logloss: 0.338522\tvalid_0's binary_logloss: 0.369246\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='dart', class_weight=None, colsample_bytree=0.5,\n",
       "               importance_type='split', learning_rate=0.1, max_depth=-1,\n",
       "               min_child_samples=20, min_child_weight=0.1, min_split_gain=0.0,\n",
       "               n_estimators=100, n_jobs=-1, num_leaves=180, objective=None,\n",
       "               random_state=42, reg_alpha=0.0, reg_lambda=1, silent='warn',\n",
       "               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, eval_set=[(x_val,y_val), (x_train,y_train)], verbose=20, eval_metric='logloss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use the model to predict for a file or specific animal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = pd.read_csv('') #insert new subset of data or specific animal record as 'csv' filetype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
